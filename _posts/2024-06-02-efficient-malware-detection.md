
# Deteksi Malware Efisien dengan NLP dan Deep Learning – Ulasan Paper Terbaru

## Masalah yang Dihadapi

Perkembangan malware modern menimbulkan urgensi tinggi dalam deteksi malware yang lebih canggih. Serangan malware seperti ransomware telah mencapai skala masif – **lebih dari 230 juta perangkat** telah terinfeksi secara global, di mana *47% korbannya adalah perusahaan besar di Amerika Serikat*. Angka ini menunjukkan betapa gentingnya ancaman malware di era teknologi saat ini. Sistem keamanan konvensional kewalahan menghadapi laju kemunculan **varian malware baru** yang kian kompleks.

**Keterbatasan Deteksi Berbasis Tanda Tangan:** Metode deteksi tradisional umumnya mengandalkan pencocokan *signature* (tanda tangan digital) dari malware yang sudah dikenali. Teknik ini memiliki kelemahan mendasar – ia *hanya efektif untuk malware yang sudah pernah ditemukan sebelumnya*. Menurut paper ini, pendekatan populer saat ini masih “bergantung pada pencocokan signature malware yang telah diketahui, sehingga tidak mampu menghadapi malware-malware baru”. Dengan kata lain, jika malware sedikit saja memodifikasi kodenya sehingga *hash* atau polanya berbeda, deteksi signature akan gagal mengenalinya. Algoritma yang bergantung pada hash seperti *MD5/SHA* dapat dengan mudah dikelabui melalui **obfuscation** (pengacakan kode) atau teknik abstraksi/pembungkusan kode. Setiap kali malware bermutasi dan lolos dari signature yang ada, diperlukan pembuatan signature baru secara manual – sebuah permainan kucing-kelinci yang tidak efisien. Seperti yang dikatakan penulis: *“Conventional malware detection techniques, such as signature matching, are constrained by the dynamic evolution of malware, which limits their adaptability and efficacy.”*. Dengan kemunculan **malware polimorfik** dan **metamorfik**, yaitu malware yang dapat mengubah diri atau mengenkripsi kodenya setiap infeksi, metode signature-based menjadi semakin rentan. Malware jenis ini sengaja memodifikasi karakteristik internalnya secara otomatis sehingga *tanda tangannya berubah-ubah*, membuat pendeteksian berbasis database signature statis menjadi kewalahan. Selain itu, penyerang juga menerapkan **teknik evasion (pengelakan)** untuk menghindari deteksi, misalnya dengan mengecek lingkungan virtual (*sandbox detection*) atau menunda eksekusi berbahaya saat terdeteksi berjalan di lingkungan analisis. Akibatnya, malware dapat “tidak beraksi” saat diuji di sandbox sehingga lolos dari deteksi tradisional.

**Peralihan ke Analisis Dinamis dan Heuristik:** Keterbatasan pendekatan static signature mendorong lahirnya metode deteksi berbasis *heuristic* dan analisis perilaku. Alih-alih hanya melihat kode biner malware, teknik heuristik menganalisis **perilaku program di lingkungan terkendali (sandbox)**. Sandbox adalah mesin virtual yang terisolasi untuk mengeksekusi file mencurigakan secara aman. Pendekatan ini memungkinkan malware dijalankan dengan akses yang dibatasi namun cukup untuk mengamati tindak-tanduknya. Tools seperti *Cuckoo Sandbox* akan mencatat *snapshot* aktivitas malware – *file* apa yang diakses, API apa yang dipanggil, koneksi jaringan yang dibuat, perubahan registry, dan sebagainya. Dari log tersebut, sistem dapat menyimpulkan apakah perilaku yang diamati bersifat malisius atau tidak. Teknik sandboxing ini tergolong revolusioner karena mampu mengungkap malware baru *berdasarkan apa yang dilakukannya*, bukan sekadar pencocokan pola statis. Pendekatan analisis dinamis seperti ini telah membantu mengidentifikasi beragam varian ransomware dan malware lain yang sebelumnya luput dari signature-based detection.

Pada saat yang sama, kemajuan pesat di bidang *Artificial Intelligence (AI)* dan *Machine Learning (ML)* turut mendorong inovasi dalam deteksi malware. Muncul metode **ekstraksi fitur otomatis**, di mana ciri-ciri malware dipelajari oleh algoritma ML untuk menemukan pola kesamaan antar sampel malware, sehingga *tidak memerlukan pencocokan persis* dengan malware dikenal. Misalnya, algoritma dapat menganalisis opcode atau *byte-sequence* file eksekusi untuk mendeteksi kemiripan dengan keluarga malware tertentu secara lebih adaptif. Pendekatan lain yang kreatif adalah **analisis malware berbasis citra** – kode biner program diubah menjadi citra grayscale, lalu model *Convolutional Neural Network (CNN)* digunakan untuk mengklasifikasikan citra tersebut sebagai malware atau benign dengan akurasi tinggi. Teknik ini memanfaatkan visi komputer untuk menemukan “pola” visual yang mewakili malware tertentu. Semua pendekatan baru ini hadir untuk mengatasi limitasi metode lama dan *beradaptasi terhadap malware yang terus berevolusi*.

**Tantangan Kontemporer:** Meski lebih unggul, metode dinamis/heuristik juga menghadapi tantangan. Malware canggih dibekali **teknik anti-sandbox** – contohnya memeriksa indikator virtualisasi, waktu sistem, atau keberadaan proses monitoring – untuk menghindari terdeteksi dalam analisis dinamis. Selain itu, volume malware baru yang sangat besar menuntut proses deteksi yang *efisien dan otomatis*. Inilah konteks yang melatarbelakangi penelitian “Efficient Malware Detection using NLP and Deep Learning Model”. Penelitian ini berangkat dari pertanyaan: *dapatkah teknik NLP (Natural Language Processing) dan deep learning diterapkan pada data perilaku malware untuk meningkatkan akurasi dan efisiensi deteksi, melampaui pendekatan konvensional?*. Secara spesifik, penelitian ini menekankan **analisis berkas perilaku (behavioral logs)** dari sandbox sebagai sumber data, lalu memanfaatkan model bahasa (*language model*) modern untuk memahami “cerita” di balik deretan aktivitas malware tersebut. Pendekatan ini mencoba memadukan keunggulan analisis perilaku *dynamic* dengan kekuatan NLP dalam mengekstrak pola dari urutan teks, menciptakan sebuah *model klasifikasi malware* berbasis deep learning yang lebih adaptif daripada metode terdahulu.

## Pendekatan yang Diterapkan

Penelitian ini mengusulkan kerangka deteksi malware dengan memanfaatkan *sandboxing*, teknik NLP (menggunakan model **BERT**), dan arsitektur deep learning tipe **Multi-Layer Perceptron (MLP)** untuk klasifikasi. Secara garis besar, alur metodologisnya dapat dijelaskan sebagai berikut:

1. **Dynamic Analysis dengan Sandbox (Cuckoo):** Pertama, sampel file yang akan dianalisis dijalankan di dalam lingkungan sandbox *Cuckoo* yang diinstal pada mesin virtual. Cuckoo akan memantau perilaku file tersebut secara terisolasi – memastikan file tidak merusak sistem asli. Sandbox mencatat berbagai **data perilaku malware** selama eksekusi, terutama *kernel API calls* (panggilan fungsi ke sistem operasi) dan aktivitas lain seperti penggunaan sumber daya. Log analisis dari sandbox (biasanya berupa laporan JSON atau CSV) kemudian diekstrak keluar dari VM untuk diproses lebih lanjut. Pendekatan *behavioural analysis* ini memastikan fokus model pada *bagaimana malware berperilaku*, bukan pada ciri statik kodenya.

2. **Ekstraksi *API Call* sebagai Fitur:** Dari log sandbox yang dikumpulkan, penelitian ini berfokus pada **deretan API call kernel** yang dilakukan oleh sampel. API call di sini merujuk pada pemanggilan fungsi-fungsi sistem (kernel) oleh program, misalnya fungsi untuk membuka file, mengubah registry, membuat proses baru, mengakses jaringan, dll. Setiap malware umumnya melakukan serangkaian API call tertentu sebagai bagian dari aksinya, sehingga urutan ini dapat dianggap seperti “kalimat” yang mendeskripsikan perilaku malware. Alasan pemilihan kernel API calls adalah karena fungsi-fungsi kernel cenderung *konsisten dan terbatas* (terstandardisasi) di seluruh aplikasi, sehingga dapat menjadi *indikator umum* yang efektif. Berbeda dengan *system call* user-level yang mungkin bervariasi tiap program, panggilan ke kernel OS mencerminkan aksi mendasar (seperti menulis berkas, mengubah memori, dsb) dan sering dijumpai pada malware. Dengan menganalisis urutan fungsi kernel yang dipanggil, diharapkan model dapat menangkap *pola perilaku* yang membedakan program jahat dan program normal.

3. **Preprocessing & Encoding Data:** Selanjutnya, data mentah berupa deretan nama-nama API call **dibersihkan dan dipreproses**. Proses cleaning mencakup menghapus data redundan atau noise dari log. Kemudian peneliti melakukan padding/uniforming sequence: setiap sampel malware diwakili oleh **urutan maksimal 50 API calls** pertama yang dilakukannya. Jika sebuah sampel hanya memiliki, misalnya, 30 panggilan API, sisanya akan di-*pad* dengan token khusus `"End"` hingga panjang 50, menandai berakhirnya urutan. Token `"End"` ini berfungsi sebagai penanda akhir yang membantu model memahami bahwa tidak ada lagi panggilan riil setelah itu, sehingga *model dapat mengabaikan slot kosong tersebut atau memberi bobot rendah padanya*. Semua API call dalam urutan kemudian dikonversi menjadi bentuk token teks (jika belum berupa teks). Dataset akhir disusun dalam bentuk tabel (CSV) berisi: hash SHA-256 file, label (malicious/benign), dan daftar API calls yang dipanggil oleh file tersebut. Selanjutnya, data label diubah menjadi biner (1 untuk malicious, 0 untuk benign), dan seluruh dataset dibagi menjadi set **pelatihan (training)** dan **pengujian (testing)** dengan proporsi 80/20. Pada penelitian ini, setelah pembersihan data diperoleh 1793 sampel (gabungan malware & benign), yang kemudian dibagi menjadi sekitar 1344 sampel untuk training dan 449 sampel untuk testing (20%). Pembagian dilakukan secara acak menggunakan *scikit-learn* untuk memastikan representativitas.

4. **Representasi *Embedding* dengan NLP (BERT):** Inilah komponen kunci inovatif dalam pendekatan ini – menerapkan **Natural Language Processing (NLP)** untuk memodelkan urutan API calls sebagai “kalimat” yang memiliki makna. Setiap token nama fungsi API akan diubah menjadi vektor numerik (*embedding vector*) berdimensi tinggi menggunakan model bahasa BERT. BERT (*Bidirectional Encoder Representations from Transformers*) dipilih karena merupakan model *transformer* state-of-the-art yang *encoder-only* dengan kemampuan menghasilkan embedding kata yang kontekstual. Dalam penelitian ini, **model BERT digunakan untuk memvektorisasi token-token API call** menjadi representasi embedding. BERT memiliki kosakata yang sangat luas dan fleksibel, sehingga mampu memberikan *representasi bermakna* bahkan untuk kata atau token fungsi yang mungkin belum pernah ditemui secara langsung. Misalnya, jika ada nama API yang unik, BERT (dengan tokenizer subword-nya) dapat mengatasinya dengan memecah menjadi sub-token atau memetakan ke embedding dekat kata serupa. Hasil transformasi BERT adalah setiap urutan 50 token API akan diwakili oleh sekumpulan vektor berdimensi 768 (karena menggunakan BERT-base dengan dimensi 768) untuk setiap token. Jadi output BERT encoder untuk satu sampel berupa matriks berukuran 50×768. Penulis menekankan bahwa transformasi ini krusial karena memungkinkan setiap fungsi direpresentasikan sebagai titik dalam *embedding space*, di mana koordinat vektor tersebut menjadi fitur yang mencerminkan karakteristik fungsi tersebut. Dengan kata lain, BERT mengkonversi “bahasa” dari urutan pemanggilan fungsi menjadi angka-angka yang dapat dipahami model ML, sambil tetap mempertahankan *konteks urutan* secara bi-directional (karena BERT melihat konteks kiri-kanan sekaligus).

5. **Pembentukan Feature Vector:** Setelah mendapatkan embedding BERT untuk setiap token dalam urutan, langkah berikutnya adalah menggabungkan informasi ini menjadi satu representasi per sampel yang siap masuk ke model klasifikasi. Penelitian ini melakukan **penyatuan (squeezing) matriks 50×768 menjadi vektor 1-dimensi** dengan panjang 38.400 fitur (50\*768). Matriks embedding \[50,768] “diratakan” menjadi array linear \[1,38400] yang merepresentasikan satu sampel file. Setiap elemen dari 38.400 dimensi tersebut pada dasarnya mewakili satu *fitur* numerik – yakni koordinat embedding dari suatu token fungsi pada posisi tertentu dalam urutan. Meskipun dimensionalitasnya tinggi, pendekatan ini memungkinkan *seluruh konteks urutan fungsi tersimpan* dalam satu vektor fitur per sampel. (Perlu dicatat, alternatif lain yang bisa digunakan misalnya mengambil vektor \[CLS] BERT sebagai representasi urutan, atau melakukan pooling, namun studi ini memilih flatten semua token embedding menjadi fitur untuk memasukkan **semua informasi detail** ke MLP). Guna mencegah overfitting pada data berdimensi besar ini, proses pelatihan menggunakan teknik regularisasi seperti **dropout** (disebut sebagai “selectively dropping certain data points” oleh penulis), serta normalisasi data input agar sebaran nilainya sesuai untuk aktivasi tertentu.

6. **Arsitektur *Multi-Layer Perceptron (MLP)*:** Dengan input vektor fitur berukuran 38.400, peneliti merancang sebuah model *deep learning* berjenis **Artificial Neural Network (ANN)** feed-forward sederhana. Arsitektur yang digunakan terdiri dari **1 stack sequential berisi 3 layer linear** (fully-connected layer) bertingkat, masing-masing diikuti oleh fungsi aktivasi tertentu. Jadi, MLP ini memiliki 3 lapisan neuron tersembunyi berurutan sebelum lapisan output. Setiap layer mengolah input menjadi representasi baru dengan bobot (*weight*) dan bias yang dilatih. Yang menarik, model final yang diusulkan **menggabungkan beberapa jenis fungsi aktivasi** di berbagai layer, alih-alih satu jenis saja. Menurut makalah, model akhirnya merupakan “*ensemble model with all Tanh, ReLU and LeakyReLU activation layers*”. Artinya, misalkan tiga layer berturut-turut menggunakan kombinasi: misal layer1 dengan ReLU, layer2 dengan Tanh, layer3 dengan Leaky ReLU (atau urutan sejenis). Pemilihan ini didasarkan pada eksperimen – penulis awalnya mencoba model MLP yang semua layer menggunakan **ReLU** (Rectified Linear Unit) dan model yang semua menggunakan **Tanh** (hyperbolic tangent), lalu menemukan masing-masing punya kelebihan dan kekurangan (detail pada bagian Hasil). Akhirnya kombinasi digunakan untuk memanfaatkan keunggulan tiap aktivasi. Aktivasi ReLU dikenal efektif mengatasi masalah *vanishing gradient* dan membuat jaringan mudah konvergen, sementara Tanh dapat membantu normalisasi output ke rentang -1 s/d 1 dan kadang meningkatkan akurasi awal, dan LeakyReLU menangani kasus dead neuron ReLU. Kombinasi ketiganya di layer berbeda memberikan efek ensemble non-linearitas yang lebih kaya, yang terbukti memberi kinerja terbaik.

7. **Proses Pelatihan Model:** Model MLP dilatih menggunakan *supervised learning*. Target output adalah label biner: **malicious (1)** atau **benign (0)**. Fungsi loss yang digunakan adalah **Binary Cross-Entropy with Logits** – yaitu cross-entropy yang cocok untuk klasifikasi biner, diaplikasikan pada logit output sebelum sigmoid. Selama *forward pass*, input vektor fitur (38.400 dimensi) melewati 3 layer linear+aktivasi dan menghasilkan **logit output** (nilai real) di neuron output tunggal. Logit ini lalu diubah menjadi probabilitas antara 0-1 melalui fungsi **sigmoid**. Probabilitas > 0.5 diklasifikasikan sebagai malware, ≤0.5 sebagai benign. Selisih antara output prediksi dan label asli dihitung sebagai *loss*. *Backward pass* kemudian dijalankan: *gradient* loss terhadap setiap parameter dihitung dan bobot-bobot jaringan diupdate menggunakan algoritma **optimasi (optimizer)** – misalnya Stochastic Gradient Descent atau Adam (paper tidak merinci, kemungkinan SGD) – dengan tujuan meminimalkan loss. Proses feed-forward dan backpropagation ini diulang untuk setiap epoch pelatihan. Peneliti menjalankan model hingga **beberapa ratus epoch** dan melaporkan bahwa model mampu mencapai akurasi \~91% tanpa overfitting yang berarti. Selama training, digunakan *batching* dan *shuffling* data untuk memastikan generalisasi. Hasil pelatihan dipantau melalui plot akurasi training vs testing per epoch – dimana terlihat kurva akurasi yang terus meningkat dan *tidak divergen* (tidak ada indikasi overfit karena akurasi test tetap sejalan dengan train).

8. **Integrasi NLP dalam Analisis Malware:** Inti metodologi ini adalah memperlakukan rangkaian API calls seperti bahasa natural yang dapat dipahami model bahasa. *Insight*-nya, kode program sebenarnya memiliki kemiripan dengan bahasa manusia (sama-sama terdiri dari “kata” berupa fungsi dan parameter) sehingga *language processing* dapat membantu *classification*. Penulis menyatakan bahwa dengan memroses “potongan bahasa” dari kode, kita dapat menemukan korelasi dalam perilaku malware yang sebelumnya luput dari analisis tradisional. Pendekatan lintas-disiplin ini mencoba “*menggabungkan aspek satu bidang (NLP) ke bidang lain (malware analysis)*”. BERT sebagai representasi bahasa memberikan model suatu “wawasan” tentang kata/fungsi yang bahkan belum pernah dilihat (unseen) berkat pengetahuan yang dipelajarinya dari korpus luas. Dengan demikian, jika ada malware baru memanggil API yang jarang digunakan, model NLP masih dapat menempatkannya dalam konteks (misal mendeteksi kemiripan semantik dengan API lain yang berbahaya). Hal ini memberikan **adaptabilitas** lebih tinggi dibanding sekadar one-hot encoding atau metode statis.

9. **Diagram Arsitektur:** *(Penulis menyertakan diagram alur arsitektur, yang secara konseptual dapat dijelaskan sebagai berikut:)* Sampel file **(suspicious file)** yang masuk akan **dicegat** terlebih dahulu sebelum diizinkan ke sistem produksi. File tersebut dimasukkan ke **Cuckoo sandbox** dimana ia dieksekusi dalam lingkungan terkendali. Sandbox merekam semua **fungsi (API) yang dipanggil** file tersebut selama interval waktu atau hingga selesai. **Laporan sandbox** kemudian diambil, difilter khususnya bagian *function calls*, lalu **dinormalisasi dan diencoding** (melalui pipeline NLP+BERT di atas) untuk selanjutnya **diklasifikasikan oleh model MLP**. Hasil klasifikasi berupa label malware/benign disertai skor kepercayaan (nilai probabilitas sigmoid) sebagai **logit prediksi**. Terakhir, **laporan analisis** beserta prediksi model dikirimkan ke administrator sistem atau modul keamanan lanjutan. Admin atau sistem kemudian dapat mengambil tindakan terhadap file tersebut (misal dikarantina atau dihapus jika terdeteksi malware). Seluruh proses ini berlangsung otomatis, sehingga dalam penerapannya sistem ini bisa menjadi komponen *scanner* di endpoint atau di gateway perusahaan, memberikan keputusan cepat apakah suatu file terindikasi malware berdasarkan *behaviour*-nya.

Pendekatan di atas membedakan dirinya dari penelitian lain terutama dalam **penggunaan komponen NLP (BERT)** untuk data malware. Sebagian besar studi sebelumnya yang menganalisis log API calls menggunakan model sekuensial seperti *Recurrent Neural Network (RNN)* atau turunannya (LSTM/GRU), atau menggunakan teknik *feature engineering* manual. Keunikan penelitian ini adalah menganggap urutan API sebagai “kalimat” dan langsung menerapkan teknik language model terbaru. Hal ini menghindari beberapa keterbatasan RNN:

* **Efisiensi dan Generalisasi:** RNN memproses input secara berurutan step-by-step; ini membuat pelatihan kurang paralel dan butuh memori lebih besar, terutama untuk urutan panjang. Transformer BERT, sebaliknya, dapat memproses token sequence *secara paralel dalam sekali input* dan menangkap *long-range dependency* lebih baik dengan mekanisme *self-attention*. Penulis mencatat bahwa RNN cenderung membutuhkan komputasi ekstra untuk memproses string sekalipun pendek, sehingga pada dataset kecil *RNN gagal generalisasi* di bawah keterbatasan resource yang ada. Hal ini terbukti ketika mereka mencoba model RNN di dataset ini – hasilnya kurang memuaskan (dibahas di hasil). Sementara itu, pendekatan berbasis transformer lebih mampu menangani data sequential kecil tanpa overfit, dan tetap mencapai akurasi tinggi.

* **Preservasi Urutan vs Konteks:** Meski MLP yang digunakan sendiri bukan model sekuensial, *informasi urutan* sudah tertanam dalam embedding BERT berkat positional encoding dan konteks dua arah. Namun, penulis juga menyadari model mereka masih memiliki keterbatasan dalam menangani *urutan waktu* secara eksplisit (lihat diskusi keterbatasan). Dibanding RNN yang intrinsiknya melangkah satu-per-satu (sehingga urutan dijaga), pendekatan ini mengandalkan BERT untuk menanamkan hubungan antar token. Keunggulannya, BERT dapat *melihat seluruh urutan sekaligus* (bidirectional) sehingga hubungan non-lokal antar API call juga tertangkap – sedangkan RNN klasik cenderung mengingat jangka pendek kecuali menggunakan LSTM. Dengan kata lain, **transformer memberikan pemahaman konteks yang lebih kaya** terhadap urutan API calls.

Secara keseluruhan, metodologi yang diterapkan dalam paper ini merupakan integrasi menyeluruh: mulai dari pengumpulan data perilaku malware secara dinamis, transformasi data tersebut ke dalam bentuk “bahasa” yang dimengerti model, hingga desain jaringan syaraf yang disesuaikan (dengan eksperimen beberapa fungsi aktivasi) untuk menghasilkan klasifikasi yang akurat. Berikutnya, kita akan melihat seberapa efektif pendekatan ini berdasarkan hasil evaluasi empirisnya.

## Hasil dan Evaluasi

Peneliti melakukan serangkaian eksperimen untuk mengukur kinerja model yang diusulkan dibandingkan metode pembanding. Evaluasi difokuskan pada **akurasi klasifikasi** dan metrik-metrik klasik *information retrieval* seperti *Precision, Recall,* dan *F1-Score*, serta analisis kurva *Precision-Recall (PR)* dan *ROC* untuk menilai kemampuan deteksi malware secara menyeluruh.

**Kinerja Model vs Baseline:** Model yang diusulkan (BERT + MLP dengan kombinasi aktivasi) berhasil mencapai performa yang kuat dalam mendeteksi malware. Pada dataset uji, **akurasi** model ini mencapai sekitar **89,3%**. Sebagai perbandingan, peneliti menguji juga beberapa model lain:

* Model **RNN** (Recurrent Neural Network) sebagai baseline sekuensial hanya memperoleh akurasi \~**55,4%** – jauh lebih rendah. RNN tampak kesulitan belajar pola malware dari dataset ini, dengan *true positive rate (TPR)* yang rendah (sekitar 31,75%) dan cenderung gagal mengenali sebagian besar sampel malware. Hal ini kemungkinan disebabkan oleh dataset yang relatif kecil dan kompleksitas RNN yang rentan overfitting dalam kondisi data terbatas. Hasil ini sejalan dengan pengamatan penulis bahwa RNN “*failed to generalize upon the small size of the data*” karena overhead komputasi yang lebih besar.
* Model **MLP dengan aktivasi ReLU saja** mencapai akurasi \~**83,9%**. Ini menunjukkan bahwa sebuah jaringan feed-forward sederhana sudah cukup efektif ketika dipadukan dengan embedding BERT, mencapai akurasi di atas 80%. Dengan ReLU, model memiliki *precision* sekitar **83,37%** dan *recall* **87,85%**, menghasilkan F1-score \~0,844. Artinya, MLP+ReLU mampu menangkap mayoritas malware (recall tinggi \~87,9%) dengan tingkat false positive yang relatif rendah (precision \~83,4% menunjukkan sebagian besar prediksi “malware” benar adanya). False Positive Rate (FPR) model ini tercatat \~15,01%.
* Model **MLP dengan aktivasi Tanh saja** memberikan akurasi serupa, \~**83,2%**. Namun metrik lainnya menunjukkan pola berbeda: *precision*-nya lebih rendah (**72,9%**), sementara *recall*-nya sangat tinggi (**88,84%**). Konsekuensinya, *F1-score* model Tanh sedikit lebih rendah (\~0,8008) dibanding model ReLU. **False Positive Rate** model Tanh mencapai \~63,63% – nilai yang jauh lebih tinggi daripada versi ReLU. Ini berarti model beraktivasi Tanh cenderung *over-sensitive* menandai file sebagai malware (banyak alarm palsu) demi menangkap hampir semua yang benar malware (recall \~88,8% sangat tinggi). Pendekatan ini kurang ideal dalam praktek, karena tingkat false alarm yang terlalu tinggi bisa merepotkan.
* **Model MLP yang Diusulkan (kombinasi aktivasi)** keluar sebagai yang terbaik dengan akurasi \~**89,31%**. Model ini mencapai keseimbangan *precision* dan *recall* yang sama-sama tinggi: precision \~**87,17%** dan recall \~**84,55%**, menghasilkan F1-score \~**0,8589** (sekitar 85,9%). Dengan kata lain, dari semua file yang diprediksi malware oleh model, \~87% benar-benar malware, dan model berhasil mendeteksi \~84,5% dari seluruh malware yang ada. Menariknya, model ini memiliki **False Positive Rate yang sangat rendah, hanya \~2,29%**. FPR \~2,3% berarti model hampir tidak pernah salah mengklasifikasikan file benign sebagai malware (hanya \~2 dari 100 file benign yang akan keliru ditandai jahat). Angka ini jauh lebih baik dibanding model ReLU (15%) maupun Tanh (63%). Hal ini menunjukkan bahwa kombinasi fungsi aktivasi mampu menurunkan alarm palsu drastis sambil tetap menjaga sensitivitas deteksi malware. Menurut penulis, keberhasilan ini menunjukkan efektifnya memadukan berbagai aktivasi yang “saling melengkapi” sehingga model dapat belajar pola lebih kompleks.

**Evaluasi dengan Confusion Matrix:** Guna memeriksa detail kesalahan model, peneliti menampilkan *confusion matrix*. Dari *confusion matrix* model akhir (Gambar 10 di paper), dapat dihitung jumlah **True Positive (TP)**, **False Positive (FP)**, **True Negative (TN)**, dan **False Negative (FN)** untuk masing-masing model. Sebagai contoh, untuk model yang diusulkan, TP = 187, FP = 5, TN = 213, FN = 44. Ini berarti dari 232 sampel yang sebenarnya malware (TP+FN), model berhasil mendeteksi 187 di antaranya (sisanya 44 lolos tidak terdeteksi), dan dari 218 sampel benign (TN+FP), model keliru menandai hanya 5 sebagai malware. Hal ini konsisten dengan *precision* \~97% pada kelas benign (213/(213+5)) dan *recall* \~81% pada kelas malware (187/(187+44)), yang selaras dengan metrik di atas. Bagi praktisi keamanan, profil kesalahan seperti ini sangat penting: model cenderung **lebih “waspada” terhadap malware (TP tinggi)** meski itu berarti sedikit malware bisa lolos (FN ada, recall 84% bukan 100%). Namun model ini **sangat jarang memberikan alarm palsu** (hanya 5 FP), sehingga dalam konteks operasional, tim keamanan tidak akan dibanjiri laporan false alarm. Pendekatan penulis memang condong memilih *false positive daripada false negative*, dengan alasan *lebih baik mengira file bersih sebagai malware (yang kemudian bisa diverifikasi manual) daripada kecolongan malware asli dianggap aman*. Dengan model yang FPR-nya hanya 2%, strategi ini menjadi feasible tanpa terlalu mengganggu.

**Kurva Precision-Recall (PR Curve):** Penulis menyajikan visualisasi kurva Precision vs Recall (Gambar 14) untuk melihat trade-off model pada berbagai threshold keputusan. Hasilnya, **kurva PR mendekati sudut atas kanan** grafik, yang menandakan model memiliki precision dan recall yang sama-sama tinggi di ambang batas optimumnya. Dinyatakan bahwa *“dari Gambar 14 dapat dilihat model mendekati titik (1,1) pada sumbu precision dan recall”*, yang mengindikasikan kombinasi keduanya nyaris ideal. Ini tentu pencapaian yang sangat baik, karena dalam tugas deteksi yang **imbalance** (biasanya jumlah benign vs malware tidak seimbang), kurva PR lebih informatif daripada akurasi biasa. Luas area di bawah kurva PR (Average Precision) model ini tinggi, menunjukkan bahwa model mampu mempertahankan precision tinggi bahkan saat recall meningkat. Sebagai perbandingan, penulis juga memplot kurva PR untuk model RNN (Gambar 19), yang tampak jauh lebih rendah – hal ini konsisten dengan precision dan recall RNN yang buruk (banyak miss dan banyak salah deteksi).

**Kurva ROC (Receiver Operating Characteristic):** Kurva ROC (Gambar 15) memetakan True Positive Rate (TPR/Recall) vs False Positive Rate (FPR) untuk berbagai threshold. ROC model yang diusulkan menunjukkan lengkungan yang menjauh tajam dari garis diagonal (baseline acak) menuju sudut kiri atas. *Area Under Curve (AUC)* ROC-nya tinggi, artinya model mampu membedakan kelas malware vs benign dengan sangat baik secara keseluruhan. Penulis mencatat kurva ROC model “menyimpang dari garis biru putus-putus (garis acak) dan lebih tajam, menunjukkan model tidak sempurna namun cukup baik dalam prediksi positifnya”. Ada sedikit indikasi *skewness*: model cenderung condong ke **prediksi positif** (malware) bahkan dengan risiko false positive, yang sengaja diinginkan seperti dijelaskan sebelumnya. Namun, berdasarkan angka FPR yang sangat rendah, bias tersebut terkendali dengan baik. *True Positive Rate (TPR)* mendekati \~82%, dengan *False Positive Rate (FPR)* \~2.3%, titik operasional yang sangat menguntungkan (tinggi di TPR, rendah di FPR). Hal ini tergambar dari ROC yang mendekati sudut atas kiri, menandakan *detector* berkinerja tinggi.

**Dibanding Metode Lain:** Hasil di atas menegaskan bahwa integrasi NLP + MLP berhasil mengungguli baseline konvensional. RNN yang diharapkan mampu menangani sequential data ternyata justru **mengalami overfitting** dan gagal mencapai akurasi memadai (hanya \~55%). Penulis menyimpulkan bahwa pada dataset kecil dan resource terbatas, “RNNs could not learn upon the data under the same resource restriction like the MLP model”. MLP ternyata lebih *lightweight* dan tetap efektif. Selain itu, pendekatan lain seperti *feature extraction + ML klasik* (mis. Random Forest, SVM) mungkin tidak memberikan konteks antar-event, sedangkan model ini secara implisit memahami urutan event lewat embedding bahasa. Dibandingkan penelitian terkait, misalnya *image-based detection*, kelebihan pendekatan NLP ini adalah **tidak perlunya konversi format** (data perilaku tetap dalam bentuk aslinya sebagai teks fungsi, tidak diubah ke citra) dan dapat memanfaatkan *transfer learning* dari model bahasa yang telah dilatih di korpus luas. Sementara metode citra memerlukan transformasi tambahan dan training CNN dari nol yang bisa lebih berat.

**Uji Coba pada Data Baru (Validasi):** Untuk mengevaluasi robustitas, peneliti juga menguji model pada **30 sampel baru** yang benar-benar tidak pernah dilihat selama training maupun testing (anggap sebagai *hold-out validation set*). Hasilnya sangat positif: model mencapai akurasi **93,33%** pada 30 sampel ini. Dari 30 file, model salah memprediksi hanya 2 file (sebagai false positive). Precision model pada set ini bahkan tercatat 100% (tidak ada false positive sama sekali) dan recall 87,5% (hanya sedikit malware yang lolos). Meski ukuran sampelnya kecil, hasil ini memberi indikasi bahwa model mampu *generalisasi* ke data baru cukup baik. Penulis menyebutkan *“model hanya menandai 2 file sebagai false positive, yang mana kondisi ideal dalam pengujian malware – lebih baik sedikit false positive daripada false negative”*. Kurva PR dan ROC untuk data validasi (Gambar 25 dan 26) juga menunjukkan luasan area tinggi, menegaskan konsistensi performa model di skenario real-world.

**Analisis Kelebihan dan Keterbatasan:** Model yang diusulkan jelas menawarkan sejumlah kelebihan:

* *Akurasi dan Adaptabilitas:* Dengan memanfaatkan NLP, model mampu meningkatkan akurasi deteksi dan lebih adaptif terhadap varian baru. Hal ini karena pendekatan bahasa memungkinkan generalisasi berdasarkan “makna” dari tindakan malware, bukan pola literal semata.
* *Rendahnya False Alarm:* Dibanding metode lain, pendekatan ini berhasil menekan false positive rate hingga sangat rendah (\~2%), sehingga cocok untuk deployment tanpa membanjiri admin dengan alarm palsu.
* *Integrasi dalam Sistem Nyata:* Penulis menggambarkan bagaimana model ini dapat diintegrasikan ke dalam pipeline XDR (Extended Detection and Response) yang banyak dipakai penyedia keamanan siber. XDR biasanya mengumpulkan data perilaku dari endpoint ke cloud sandbox untuk analisis. Model ini dapat diterapkan di level sandbox cloud tersebut untuk memberikan konteks tambahan dalam deteksi. Artinya, pendekatan ini selaras dengan tren industri yang memanfaatkan data perilaku kolektif dalam cloud security.

Namun demikian, penelitian ini juga mengakui beberapa **keterbatasan** yang membuka ruang pengembangan lanjutan:

* **Kurangnya Pemodelan Urutan Secara Eksplisit (Proceduralism):** Meskipun menggunakan BERT menyiratkan pemahaman urutan, arsitektur akhir MLP *tidak eksplisit mempertahankan dependensi antar-step eksekusi*. Model ini “*lacks sequential methods that most computers and almost all malwares rely on*”. Malware sering melakukan aksi dalam urutan logis (misal: drop file lalu eksekusi file tersebut). *Impact of sequential call*: model saat ini mengabaikan bagaimana satu panggilan fungsi memengaruhi panggilan berikutnya. Hubungan kausal atau temporalis antar API mungkin kurang tertangkap sepenuhnya. Solusi ke depan yang diusulkan penulis adalah **mengintegrasikan model berorientasi urutan**, misalnya *transformer yang lebih canggih atau model LSTM* di tahap tertentu, agar *ordering* tetap terjaga. Mereka juga menyarankan penggunaan *attention mechanisms* untuk memperlihatkan pengaruh antar panggilan (misal perhatian mana call yang memicu call lain).
* **Data dan Sumber Daya Terbatas:** Model dilatih dan diuji pada dataset yang relatif kecil (hanya ribuan sampel). Penulis mengakui bahwa pendekatan ini masih “highly successful, *however it lacks in many fields*” dan membutuhkan penyempurnaan. Salah satu hal utama adalah **keterbatasan data dan komputasi** selama riset. Disebutkan *“model was created under high restrictions on computing power and lacks data”*. Untuk penggunaan di dunia nyata, model perlu dilatih dengan dataset yang lebih besar dan variatif (mencakup berbagai keluarga malware, malware terbaru, dsb) serta dengan resource komputasi memadai agar benar-benar robust. Misalnya, melatih ulang/fine-tuning BERT secara penuh pada corpus malware API calls yang jauh lebih besar mungkin akan meningkatkan performa lebih tinggi lagi.
* **Generalisasi ke Jenis Malware Lain:** Studi ini fokus pada **binary classification (malicious vs benign)**. Satu arah lanjutan adalah mengembangkan *multiclass classification* untuk mengidentifikasi **famili malware** atau tipe ancaman spesifik. Pendekatan NLP berpotensi diadaptasi ke tugas tersebut, misal dengan mengganti output layer menjadi multi-label dan melatih model untuk mengenali kelas ransomware vs trojan vs worm, dll. Tantangannya, tentu, ketersediaan label family dan data yang cukup.
* **Teknik Ensemble dan Hybrid:** Hasil menunjukkan kombinasi aktivasi memberi peningkatan. Ke depan, kombinasi arsitektur berbeda juga bisa dijajaki. Misal, mengombinasikan *CNN (untuk fitur statik binary)* + *RNN/Transformer (untuk API sequence)* + *MLP*, atau melakukan **ensemble beberapa model** (voting antara model berbasis NLP, berbasis image, berbasis graph permission, dsb). Hal ini dapat meningkatkan deteksi dengan menangkap sudut pandang berbeda dari malware.
* **Evasion Terhadap Model AI:** Suatu model ML pun bisa menjadi target evasi oleh malware. Misalnya, malware dapat mencoba menghasilkan deret API yang tampak normal (meniru pola program benign) untuk mengecoh model. Penelitian lanjutan perlu memastikan model tahan terhadap teknik adversarial semacam itu. Pendekatan NLP bisa rentan terhadap perturbasi urutan token; oleh karena itu, memasukkan fitur lain (seperti frekuensi panggilan, durasi antar-call, dsb) mungkin diperlukan agar model tidak mudah ditipu.

Penelitian “Efficient Malware Detection using NLP and Deep Learning Model” ini memberikan kontribusi berharga dengan menunjukkan bahwa *bahasa program* dapat dimanfaatkan untuk deteksi malware. **Integrasi sandboxing dan NLP** terbukti meningkatkan akurasi dan adaptivitas deteksi, mengatasi banyak keterbatasan metode signature-based tradisional. Hasil-hasil eksperimen memperlihatkan performa sangat menjanjikan, di mana model mencapai kombinasi precision-recall tinggi (mendekati ideal) dengan false alarm minimal. Meskipun masih ada ruang peningkatan khususnya dalam hal sequential modeling dan perluasan dataset, pendekatan ini membuka jalan baru untuk riset *malware analysis*. Para mahasiswa S2 dan peneliti di bidang keamanan siber dapat mengambil pelajaran bahwa teknik NLP tidak terbatas pada teks linguistik semata, tetapi dapat diterapkan pada “bahasa” lain seperti jejak eksekusi program. Dengan model transformer seperti BERT, sistem deteksi malware dapat “memahami” aksi program jahat layaknya membaca sebuah kalimat, sehingga mampu beradaptasi pada trik-trik baru yang dipakai malware. **Deteksi malware berbasis NLP** ini merupakan arah riset interdisipliner yang prospektif, dan di masa depan bisa dikombinasikan dengan pendekatan keamanan lain untuk membangun pertahanan yang lebih tangguh terhadap ancaman siber.
